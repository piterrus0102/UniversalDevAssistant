================================================================================
ПРОЕКТ: Universal Dev Assistant
================================================================================

ОПИСАНИЕ ПРОЕКТА:
Это универсальный AI-ассистент разработчика на Kotlin, который подключается к 
ЛЮБОМУ проекту и отвечает на вопросы о его структуре, коде и документации.

Создан для AIAdvent4Thread - День 20 (Ассистент разработчика).

================================================================================
ЧТО ДЕЛАЕТ ЭТОТ ПРОЕКТ:
================================================================================

1. RAG (Retrieval-Augmented Generation)
   - Индексирует документацию проекта (README.md + docs/)
   - Ищет релевантные куски по вопросу
   - Передает контекст в LLM для ответа

2. Векторизация (Ollama)
   - Использует локальную модель mxbai-embed-large
   - Семантический поиск по документации
   - Fallback на keyword search если Ollama недоступна

3. AI (HuggingFace)
   - Модель: Qwen/Qwen2.5-7B-Instruct
   - Генерирует ответы на основе найденной документации
   - API key взят из другого проекта AIAdvent4Thread

4. Git MCP (Model Context Protocol)
   - Выполняет git команды в целевом проекте
   - git branch, git status, git log и т.д.
   - Добавляет git-контекст в ответы

5. HTTP API (Ktor)
   - GET /help?q=вопрос - главный endpoint
   - GET /git/status, /git/branch
   - GET /docs - список документов

================================================================================
АРХИТЕКТУРА:
================================================================================

/src/main/kotlin/
  ├── Main.kt                          Entry point, инициализация всех компонентов
  │
  ├── ai/
  │   └── HuggingFaceClient.kt         LLM клиент для Qwen/Qwen2.5-7B-Instruct
  │
  ├── rag/
  │   ├── OllamaClient.kt              Векторизация через Ollama (mxbai-embed-large)
  │   └── RAGService.kt                Индексация + поиск документов
  │
  ├── mcp/
  │   └── GitMCP.kt                    Git команды (branch, status, log, etc)
  │
  ├── server/
  │   └── AssistantServer.kt           HTTP сервер на Ktor, REST API
  │
  ├── config/
  │   └── ProjectConfig.kt             Загрузка config.yaml
  │
  └── model/
      └── Document.kt                  Модель документа

config.yaml                            Главный конфиг (путь к проекту, AI ключи)
build.gradle.kts                       Gradle конфигурация (Kotlin, Ktor, etc)

================================================================================
КАК ЭТО РАБОТАЕТ (ПРИМЕР):
================================================================================

1. Пользователь: curl 'http://localhost:3002/help?q=структура проекта'

2. AssistantServer получает запрос

3. RAGService:
   - Индексирует README.md + docs/ из целевого проекта
   - Векторизует вопрос через OllamaClient
   - Находит 3 самых релевантных документа (cosine similarity)

4. GitMCP:
   - Выполняет git branch в целевом проекте
   - Получает текущую ветку, статус

5. HuggingFaceClient:
   - Получает контекст (документация + git info)
   - Отправляет в Qwen/Qwen2.5-7B-Instruct
   - Генерирует ответ

6. Возвращает JSON:
   {
     "project": "zayobushek",
     "question": "структура проекта",
     "answer": "Проект состоит из...",
     "sources": ["README.md", "docs/01_СТРУКТУРА.md"]
   }

================================================================================
КОНФИГУРАЦИЯ (config.yaml):
================================================================================

project:
  name: "zayobushek"                   Имя проекта для анализа
  path: "/Users/.../zayobushek"        ПОЛНЫЙ путь к проекту
  docs:                                Что индексировать
    - "README.md"
    - "docs/*.md"
  ignore:                              Что игнорировать
    - "node_modules"
    - ".git"

ai:
  provider: "huggingface"
  model: "Qwen/Qwen2.5-7B-Instruct"
  api_key: "your_huggingface_api_key_here"
  api_url: "https://router.huggingface.co/v1/chat/completions"

vectorization:
  enabled: true                        Включить векторизацию?
  ollama_url: "http://localhost:11434"
  model: "mxbai-embed-large"

git:
  enabled: true                        Включить Git MCP?

server:
  port: 3002
  host: "0.0.0.0"

================================================================================
ЗАВИСИМОСТИ:
================================================================================

ОБЯЗАТЕЛЬНЫЕ:
- JDK 17+
- Gradle (через gradlew wrapper)

ОПЦИОНАЛЬНЫЕ (но желательные):
- Ollama (для векторизации)
  Установка: brew install ollama
  Запуск: ollama serve
  Модель: ollama pull mxbai-embed-large

ВНЕШНИЕ СЕРВИСЫ:
- HuggingFace API (ключ уже в config.yaml)
- Ollama (локально на :11434)

================================================================================
ЗАПУСК:
================================================================================

1. Через скрипт:
   ./START.sh

2. Вручную:
   # Терминал 1 (опционально): Ollama
   ollama serve
   
   # Терминал 2: Субагент
   ./gradlew run

3. Тестирование:
   curl http://localhost:3002/health
   curl http://localhost:3002/git/branch
   curl 'http://localhost:3002/help?q=как устроен проект'

================================================================================
ИНТЕГРАЦИЯ С AIAdvent4Thread:
================================================================================

Этот проект использует компоненты из другого проекта:
/Users/ruslanhafizov/Desktop/AIAdvent4Thread/

ЧТО ВЗЯТО:
1. HuggingFace LLM - из mcp-proxy/server/HuggingFaceClient.js
   Переписано на Kotlin в ai/HuggingFaceClient.kt

2. Ollama векторизация - из rag-proxy/VectorizationClient.js
   Переписано на Kotlin в rag/OllamaClient.kt

3. RAG сервис - из rag-proxy/RAGService.js
   Переписано на Kotlin в rag/RAGService.kt

4. API ключи - из mcp-proxy/.env
   HUGGINGFACE_API_KEY=your_huggingface_api_key_here

================================================================================
КЛЮЧЕВЫЕ ФАЙЛЫ:
================================================================================

Main.kt                - Точка входа, инициализация компонентов
AssistantServer.kt     - HTTP сервер, роутинг, endpoint /help
RAGService.kt          - Индексация документов, векторный поиск
OllamaClient.kt        - Генерация embeddings через Ollama
HuggingFaceClient.kt   - Обращение к Qwen LLM
GitMCP.kt              - Выполнение git команд
ProjectConfig.kt       - Загрузка config.yaml
config.yaml            - Главный конфиг (РЕДАКТИРУЙ ЗДЕСЬ путь к проекту)

================================================================================
ENDPOINTS API:
================================================================================

GET /                          - Список всех endpoints
GET /health                    - Health check
GET /help?q=вопрос            - ГЛАВНЫЙ: задать вопрос о проекте
GET /git/status               - Git статус
GET /git/branch               - Текущая ветка
GET /git/info                 - Полная git информация
GET /docs                     - Список проиндексированных документов
GET /docs/{path}              - Содержимое конкретного документа

================================================================================
WORKFLOW РАЗРАБОТКИ:
================================================================================

1. Если нужно подключить к ДРУГОМУ проекту:
   - Отредактируй config.yaml (секция project)
   - Измени path на новый проект
   - Перезапусти ./gradlew run

2. Если нужно добавить новые эндпоинты:
   - Редактируй server/AssistantServer.kt
   - Добавь новый route в routing { ... }

3. Если нужно изменить логику поиска:
   - Редактируй rag/RAGService.kt
   - Методы: search(), searchVector(), buildContext()

4. Если нужно добавить новые git команды:
   - Редактируй mcp/GitMCP.kt
   - Добавь новый метод executeGit(...)

================================================================================
ВАЖНЫЕ ДЕТАЛИ:
================================================================================

1. Векторизация ОПЦИОНАЛЬНА
   - Если Ollama недоступна → keyword search
   - Логи покажут: "Векторизация отключена (keyword search)"

2. config.yaml НЕ в .gitignore
   - Но в примере (config.yaml.example) ключи замаскированы

3. Проект УНИВЕРСАЛЬНЫЙ
   - Меняешь config.yaml → работает с другим проектом
   - Не привязан к zayobushek

4. Kotlin + JVM
   - Типобезопасность
   - Null-safety
   - Работает на любой ОС (Mac, Linux, Windows)

5. Ktor сервер
   - Асинхронный
   - JSON из коробки
   - Легко расширяется

================================================================================
ЦЕЛЬ ПРОЕКТА (AIAdvent - День 20):
================================================================================

Требования:
✅ RAG для подключения к документации (README + docs)
✅ MCP для git-репозитория (git branch)
✅ Команда /help отвечает на вопросы о проекте

Дополнительно сделано:
✅ Векторизация через Ollama (семантический поиск)
✅ HuggingFace LLM (Qwen 2.5)
✅ Полная Git интеграция (status, log, commits)
✅ REST API с множеством endpoints
✅ Написано на Kotlin (не Node.js)
✅ Универсальность для любого проекта

================================================================================
TROUBLESHOOTING:
================================================================================

Ошибка: "Ollama недоступна"
→ Запусти: ollama serve
→ Проверь: curl http://localhost:11434

Ошибка: "HuggingFace API error"
→ Проверь api_key в config.yaml
→ Модель может загружаться (подожди 30 сек)

Ошибка: "Git command failed"
→ Проверь project.path в config.yaml
→ Проверь что это git репозиторий: cd /path && git status

Ошибка: "Config file not found"
→ Создай: cp config.yaml.example config.yaml

================================================================================
СЛЕДУЮЩИЕ ШАГИ:
================================================================================

1. Прочитай README.md для полной документации
2. Прочитай INTEGRATION.md для деталей интеграции
3. Отредактируй config.yaml под свой проект
4. Запусти ./START.sh
5. Тестируй через curl или браузер

================================================================================
ПРИМЕРЫ ИСПОЛЬЗОВАНИЯ:
================================================================================

# Вопрос о структуре
curl 'http://localhost:3002/help?q=как устроен проект'

# Вопрос о конкретном файле
curl 'http://localhost:3002/help?q=что делает AuthController'

# Вопрос о API
curl 'http://localhost:3002/help?q=где документация API'

# Git информация
curl http://localhost:3002/git/status

# Список документов
curl http://localhost:3002/docs

================================================================================
КОНЕЦ КОНТЕКСТА
================================================================================

Это полный контекст проекта Universal Dev Assistant.
Используй эту информацию для помощи в разработке, отладке и расширении проекта.

